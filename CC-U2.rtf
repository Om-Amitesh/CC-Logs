{\rtf1\ansi\ansicpg1252\cocoartf2636
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 Helvetica-Bold;\f2\fnil\fcharset0 AppleColorEmoji;
}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww28600\viewh18000\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs66 \cf0 VMs\

\fs42 Virtualisation in this context is actually making your resource pool appear as separate execution environments for things to run.\
\
Why VMs?\
OS diversity\
Security and isolation\
Encapsulating \
Support load balancing over a cluster/grid\
\
Hypervisor/VMM : this is a layer that sits over your hardware and host OS and enables these set of resources to be virtualised. \
\
Goals for a VMM:\
	> Execution environments provided must be as though it is running on a separate/actual machine only\
	> Despite Emulation it should not show decrease in performance or speed\
	> It should have complete control over resources to allocate required amounts.\
\
Types of VMs:\
	> Bare metal VMs : These VMs run directly run on hardware without a host OS. the hardware is supposed to support this. This is called Hardware virtualisation.\
	> Hosted VMs: These VMs would run on top of a Host OS layer. KVMs - Kernel VMs come under this. Kernel VMs enable the host OS also to behave like a hypervisor. This is called OS virtualisation.\
	> Hybrid VMs? Yeah these are possible, its better to look at a diagram to understand this.
\fs66 \

\fs42 \
Types of Virtualisation:\
	> Full/Transparent Virtualisation: Here the guest OS is not modified and it runs as is on the resources you allot to it, via the hypervisor. VMWare comes here.\
	> Para-Virtualisation: The guest OSes are modified here to run on your allocated resources. The VMM/hypervisor in this case provides APIs for the guest OS to carry out the right function calls or so. \
APIs(called hyper-calls) provided by the VMMs here try to resolve the performance issue which occurs by manual binary translation that you\'92d do in full virtualisation. The VMM here does the work of translating the API calls to system calls. Certain commands that are read only can go directly to the host computer though, no need for API call to VMM.\

\fs66 \
VM Migration\

\fs46 \

\fs42 VM Migration is basically switching VMs over to other nodes in the cluster.\

\fs40 (VM Migration can happen from one cluster to another too, but it isn\'92t termed as VM Migration then).
\fs46 \

\fs38 Live migration: In cloud computing we promise uninterrupted service, in order to facilitate that we must ensure if we have to switch VMs between nodes, we gotta do a live transfer.\
VM Migration doesn\'92t actually guarantee really good QoS - there\'92s a lot of overhead on switching a VM to another machine.\
VM Migration itself is a process that we\'92ll need to handle. ~ despite whatever the client throws at us at the same time.\
\
In order to please greta thunberg, we\'92ll have keep things energy efficient when we switch VMs. (You can be in school, kid)\
\
More reasons why VMM?\
\
	> Fault Tolerance - Expected failure on burdened machines\
	> Maintenance - well, let\'92s say node A has to go on scheduled downtime, node B temporarily has to handle the VM that was supposed to be at node A. Why? Cause client kill me for no service otherwise.(downtime why? firmware upgrade, etc)\
	> 
\f1\b Load Balancing 
\f0\b0 - the main purpose, we\'92re tryna achieve max efficiency (engineer instincts). Gotta use all the resources we have.\
\
How tf does this happen?\
	> 6 step process:\
		> step 0: Figure out 
\f1\b where
\f0\b0  to migrate the VM(s) to -\
			find the node within your cluster with lower load and can support the VM you\'92re trying to migrate\
			Keep the VM running while you\'92re at it.\
		> step 1: 
\f1\b Reserve
\f0\b0  the Node -\
			node A: \'93yo node B, I need to send you this VM, keep these resources for it\'94\
			node B: \'93Gotchu fam.
\f2 \uc0\u55357 \u56397 \u55356 \u57339 
\f0 \'94\
			node C: \'93can I use those resources, node B\'94\
			node B: \'93My(these) resources only belong to A <3\'94\
		> step 2: Iterative 
\f1\b pre-copy
\f0\b0 :\
			Let\'92s keep you spoiler free, iterative pre copying is a process of copying for now.\
			(if you\'92re curious, you\'92re gonna copy the \'91dirty\'92 pages to the other node in successive rounds.\
		> step 3: stop and copy\
			The VM instance on node A is shut down and and ARP is used to redirect traffic to host B\
			We also sync the remaining VM state params to node B\
		> step 4: 
\f1\b commitment \
			
\f0\b0 VM state on host A is released.\
		> step 5: VM activation at destination server:\
			After the required data is transferred, node B then starts the VM resuming the state and the programs that were running on it before migration.\
\
What are the problems with VM migration?\
	Memory migration is one of the challenges that we face with VM Migration.	Internet suspended resume technique exploits temporal locality of reference.\
	To exploit temporal locality, each file in the file system is represented as a tree of small subfiles. A copy of this tree exists in both the suspended and resumed VM instances. The advantage of using a tree-based representation of files is that the caching ensures the transmission of only those files which have been changed.\
<request to continue after understanding the slides>\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\fs58 \cf0 Containers\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\fs40 \cf0 \
What is a container?\
	Containers are packages of software that contain all of the necessary elements to run in any environment	Containers DO NOT have their own OSes.\
	Containers - LXC uses linux kernels cgroups and namespaces to isolate different containers.\
	What\'92s different from a VM?\
		VMs virtualise hardware resources, Containers virtualise software resources.\
\
Why tf did I start building containers, when I had VMs that did the task already?\
	Isolation achieved by VMs is costly.\
	Things like VMMigration that we learnt earlier, is super costly and even has a risk of failure\
	We really need to think of lightweight methods to support isolated resources over a resource pool.\
	Management of multiple OSes over hardware is hard, using a unified kernel for multiple isolated environments seems more of a logical solution if you think about it.\
	Since containers are not specific to OSes, rather specific to their container engine, you can deploy it elsewhere with a MUCH lower overhead.\
\
How are we gonna manage containers? what makes this work?\
Enter : Docker.\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\fs54 \cf0 Docker:\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\fs40 \cf0 	Docker is an open source containerisation platform that lets you package applications to containers.\
	You can say this is a container engine, that makes this work.\
	It can help you create, test, ship and deploy containers too.\
	It can be looked at as a PaaS product that lets you have OS level virtualisation to deliver S/W packages\
	OS level virtualisation lets you have multiple user spaces over a single OS.\
	\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\fs64 \cf0 Namespaces in CC\

\fs50 \

\fs36 What is a namespace?\
	> namespaces in linux enable a process to partition one set of resource that is required for it to execute.\
	> Why we do this? Isolation. This lets us isolate say multiple users that are accessing the cloud for its resources.\
	> Does docker use namespaces while building containers?\
		Docker implements namespaces by keeping track of 10 major system features ~this lets us perfectly isolate containers when they\'92re executing something:\
			> PID namespace: by process level - process ID\
			> UTS namespace: Unix Timesharing system\
			> MNT namespace: mount points-where in the FS the namespace is\
			> IPC : uses a shared memory namespace\
			> NET namespace: This namespace is based off IP address and ports, this is defined by the network structure\
			> USR namespace: This namespace is differentiated by different users\
			> chroot syscall: this lets you control the root(/)\
			> cgroups: control groups are a hierarchal group collection that gives a specific set of permissions in each group.\
			> CAP drop: this lets you restrict OS features.\
			> Security modules: \'93Mandatory access controls\'94 <readup online>\
MNT namespaces:\
	This works by using the file path/ mount location as a differentiator that lets you distinguish users.\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\fs66 \cf0 Kubernetes Architecture:\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\fs36 \cf0 Kubernetes uses a master-slave architecture:\
<Explain wtf masters and slaves do here>\
Master node components:\
	> etc - et cetra distributed\
	> API server\
	> Scheduler\
	> Controller-Manager\
What does the API Server?\
	> Exposes the API and the entry points for all the REST commands\
Etcd? Sounds familiar?\
	> Etc is a directory in the linux FS that has stores storage system configuration files, executables required to boot the system, and some log files.\
	> master nodes have an etc - distributed version of the etc FS\
Worker Node Components:\
	> Kubelet (sounds like something cute) : this is an agent that makes sure that the containers that are under the API are up-and-running.\
	> Kube Proxy: kube-proxy is a network proxy that runs on each node in your cluster, implementing part of the Kubernetes Service concept. kube-proxy maintains network rules on nodes. These network rules allow network communication to your Pods from network sessions inside or outside of your cluster.\
	> Container runtime: this runs containers - the whole point of doing this\
	> CRI : Conteiner runtime interface, this helps you communicate with container runtimes\
\
Some clicky stuff for this : {\field{\*\fldinst{HYPERLINK "https://www.appvia.io/blog/components-of-kubernetes-architecture"}}{\fldrslt https://www.appvia.io/blog/components-of-kubernetes-architecture}}\
\
\
}